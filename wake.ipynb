{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wake word detection\n",
    "This notebook implements a wake-word detector. A wake word detector is used to trigger an event in a program upon the utterance of a wake word (similar to \"Hey Siri\" in Apple devices and \"OK Google\" in Google devices). It uses a deep recurrent neural network based on gated recurrent units. The training and development data is synthesized from audio samples (of backgrounds, wake words, and negatives), which can easily be generated using the recording section in this notebook. The pre-trained weights are then loaded and the model is fine tuned to the newly added audio samples.\n",
    "\n",
    "This notebook uses the model and pre-trained weights from the [Coursera](https://www.coursera.org/) course on sequence models. \n",
    "\n",
    "The notebook is organized as follows:\n",
    "\n",
    "- [0. Imports](#0)\n",
    "- [1. Record audio samples for trigger, negatives, background, and test sets](#1)\n",
    "- [2. Synthesize training and test sets](#2)\n",
    "- [3. Build the model (with gated recurrent units)](#3)\n",
    "- [4. Load pre-trained weights](#4)\n",
    "- [5. Fine-tune the model](#5)\n",
    "- [6. Evaluation and prediction](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## 0. Imports\n",
    "This notebook requires `tensorflow`, `pydub`, `numpy` and `scipy`. For in-notebook recording of audio (in [section 1](#1)), `sounddevice`, `soundfile`, `ipywebrtc`, and `ffmpeg` are required in addtion.\n",
    "\n",
    "The local module `utils` contains various functions required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "from utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1. Record audio samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Record wake word and negatives\n",
    "Record multiple trigger words and negatives using `ipywebrtc`. If the pre-trained weights are going to be used, the wake word is '**activate**'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebrtc import AudioRecorder, CameraStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audiodevice = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=audiodevice)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathwake = 'audio/trigger/'\n",
    "pathnegative = 'audio/negatives/'\n",
    "\n",
    "# Uncomment the savesample for the wake word or negative. Make sure that\n",
    "# only one is uncommented.\n",
    "\n",
    "# wake word\n",
    "#savesample(recorder, pathwake)\n",
    "\n",
    "# negative word\n",
    "#savesample(recorder, pathnegative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Record background and test audio samples\n",
    "These need to be 10s long and are recorded with `sounddevice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 44100\n",
    "duration = 10\n",
    "backgroundpath = 'audio/backgrounds/'\n",
    "testpath = 'audio/test/'\n",
    "\n",
    "# Uncomment the savesample for the wake word or negative. Make sure that\n",
    "# only one is uncommented.\n",
    "\n",
    "# background\n",
    "#recordsample(backgroundpath, duration, samplerate)\n",
    "\n",
    "# test set\n",
    "#recordsample(testpath, duration, samplerate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Listen to audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPython.display.Audio(\"./audio/trigger/s_1.wav\")\n",
    "#IPython.display.Audio(\"./audio/negatives/s_1.wav\")\n",
    "#IPython.display.Audio(\"./audio/backgrounds/1.wav\")\n",
    "#IPython.display.Audio(\"./audio/test/1.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2. Synthesize training and test sets\n",
    "\n",
    "To generate a larger data set from the samples one can superimpose various wake words and negative words with the recorded backgrounds. The input data of the recurrent network is spectral and can be obtained by supplying the raw audio data to the function `graph_spectrogram`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = graph_spectrogram(\"audio/backgrounds/1.wav\")\n",
    "_, data = wavfile.read(\"audio/backgrounds/1.wav\")\n",
    "print(\"Time steps in audio recording before spectrogram\", data.shape)\n",
    "print(\"Time steps in input after spectrogram\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant dimensions of the problem are:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_freq = 44100  # sampling frequency\n",
    "Tx = 5511 # The number of time steps input from the spectrogram\n",
    "n_freq = 101 # Number of frequencies input at each time step of the spectrogram\n",
    "Ty = 1375 # The number of time steps in the output of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Load audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = './audio/'\n",
    "triggers = []\n",
    "backgrounds = []\n",
    "negatives = []\n",
    "for filename in os.listdir(path + \"trigger\"):\n",
    "    if filename.endswith(\"wav\"):\n",
    "        trigger = AudioSegment.from_wav(path + \"trigger/\" + filename)\n",
    "        assert trigger.frame_rate==s_freq, f\"All audio files must be sampled at {s_freq}Hz\"\n",
    "        triggers.append(trigger)\n",
    "for filename in os.listdir(path + \"backgrounds\"):\n",
    "    if filename.endswith(\"wav\"):\n",
    "        background = AudioSegment.from_wav(path + \"backgrounds/\" + filename)\n",
    "        assert trigger.frame_rate==s_freq, f\"All audio files must be sampled at {s_freq}Hz\"\n",
    "        backgrounds.append(background)\n",
    "for filename in os.listdir(path + \"negatives\"):\n",
    "    if filename.endswith(\"wav\"):\n",
    "        negative = AudioSegment.from_wav(path + \"negatives/\" + filename)\n",
    "        assert trigger.frame_rate==s_freq, f\"All audio files must be sampled at {s_freq}Hz\"\n",
    "        negatives.append(negative)\n",
    "\n",
    "print(\"Number of background samples: \\n\" + str(len(backgrounds)),\"\\n\")\n",
    "print(\"Number of wake word samples \\n\" + str(len(triggers)),\"\\n\")\n",
    "print(\"Number of negative samples \\n\" + str(len(negatives)),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Generate training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(454)\n",
    "nsamples = 64\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(0, nsamples):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    x, y = create_training_example(backgrounds[i % 2], triggers, negatives, Ty)\n",
    "    X.append(x.swapaxes(0,1))\n",
    "    Y.append(y.swapaxes(0,1))\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(18)\n",
    "x, y = create_training_example(backgrounds[0], triggers, negatives, Ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated training set example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(\"train.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output data of the model is a vector containing ones at the time stamps right after the wake word was said:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Generate dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'audio/dev/'\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\"wav\"):\n",
    "        os.remove(path+filename)\n",
    "\n",
    "nsamples = 8\n",
    "X_dev = []\n",
    "Y_dev = []\n",
    "for i in range(0, nsamples):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    x, y = create_training_example(backgrounds[i % 2], triggers, negatives, Ty, path)\n",
    "    X_dev.append(x.swapaxes(0,1))\n",
    "    Y_dev.append(y.swapaxes(0,1))\n",
    "    \n",
    "X_dev = np.array(X)\n",
    "Y_dev = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3. Build the model (with gated recurrent units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelf(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    # Convolutional layer\n",
    "    X = Conv1D(filters=196,kernel_size=15,strides=4)(X_input)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(rate=0.8)(X)                                  \n",
    "\n",
    "    # First GRU Layer\n",
    "    X = GRU(units=128, return_sequences=True)(X)\n",
    "    X = Dropout(rate=0.8)(X) \n",
    "    X = BatchNormalization()(X)                           \n",
    "    \n",
    "    # Second GRU Layer\n",
    "    X = GRU(units=128, return_sequences=True)(X)\n",
    "    X = Dropout(rate=0.8)(X)        \n",
    "    X = BatchNormalization()(X)   \n",
    "    X = Dropout(rate=0.8)(X)                                    \n",
    "    \n",
    "    #Time-distributed dense layer\n",
    "    X = TimeDistributed(Dense(1, activation='sigmoid'))(X) \n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelf(input_shape = (Tx, n_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4. Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open('./models/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('./models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5. Fine-tune the model\n",
    "Freeze BatchNorm layers for fine-tuning of loaded model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = False\n",
    "model.layers[7].trainable = False\n",
    "model.layers[10].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Adam optimizer and binary crossentropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-6, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X, Y, batch_size = 16, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6. Evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Dev set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, = model.evaluate(X_dev, Y_dev)\n",
    "print(\"Dev set accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = \"./audio/test/1.wav\"\n",
    "prediction = detect_wakeword(model, filename)\n",
    "bell_on_activate(filename, prediction, 0.5)\n",
    "IPython.display.Audio(\"./bell_output.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
